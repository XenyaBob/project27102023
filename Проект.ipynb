{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "17490c74",
   "metadata": {},
   "source": [
    "# Описание проекта - Бобкова Ксения"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30356476",
   "metadata": {},
   "source": [
    "В данной тетрадке кратко описано выполнение поставленной задачи. Файлы с кодом и полученной базой данных также есть в Гитхабе."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1f791af",
   "metadata": {},
   "source": [
    "Написание кода состояло из двух основных этапов: создание базы данных (включая предобработку текстов) и написание функции поиска."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a44aebdd",
   "metadata": {},
   "source": [
    "### Создание базы данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5805e8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "from pymystem3 import Mystem\n",
    "import nltk\n",
    "import os\n",
    "import glob\n",
    "\n",
    "#Создание таблиц для базы данных\n",
    "def get_db_connect(db_name):\n",
    "  conn = sqlite3.connect(db_name)\n",
    "  cur = conn.cursor()\n",
    "\n",
    "  cur.execute(\"CREATE TABLE IF NOT EXISTS text\"\n",
    "              \" (text_id INTEGER PRIMARY KEY AUTOINCREMENT, text_info TEXT UNIQUE);\")\n",
    "\n",
    "  cur.execute(\"CREATE TABLE IF NOT EXISTS sentence\"\n",
    "              \" (sent_id INTEGER PRIMARY KEY AUTOINCREMENT, text_id INTEGER, sent_text TEXT);\")\n",
    "\n",
    "  cur.execute(\"CREATE TABLE IF NOT EXISTS onegramm\"\n",
    "              \" (sent_id INTEGER, word_index INTEGER, word_id INTEGER, word_ind, word_form TEXT\"\n",
    "              \", CONSTRAINT primarykey_sent_word PRIMARY KEY (sent_id,word_index,word_id));\")\n",
    "\n",
    "  cur.execute(\"CREATE TABLE IF NOT EXISTS bigramm\"\n",
    "              \" (sent_id INTEGER, word_index INTEGER, word1_id INTEGER, word1_form TEXT, word2_id INTEGER, word2_form TEXT\"\n",
    "              \", CONSTRAINT primarykey_sent_word1_word2 PRIMARY KEY (sent_id,word_index,word1_id,word2_id));\")\n",
    "\n",
    "  cur.execute(\"CREATE TABLE IF NOT EXISTS trigramm\"\n",
    "              \" (sent_id INTEGER, word_index INTEGER, word1_id INTEGER, word1_form TEXT, word2_id INTEGER, word2_form TEXT, word3_id INTEGER, word3_form TEXT\"\n",
    "              \", CONSTRAINT primarykey_sent_word1_word2_word3 PRIMARY KEY (sent_id,word_index,word1_id,word2_id,word3_id));\")\n",
    "\n",
    "  cur.execute(\"CREATE TABLE IF NOT EXISTS word\"\n",
    "              \" (word_id INTEGER PRIMARY KEY AUTOINCREMENT, lemma TEXT, pos_tag TEXT\"\n",
    "              \", CONSTRAINT lemma_pos_tag UNIQUE (lemma,pos_tag));\")\n",
    "\n",
    "  conn.commit()\n",
    "\n",
    "  return conn\n",
    "\n",
    "#Обработка файлов с текстами и запись полученных из них данных в таблицы (в цикле по папке)\n",
    "#1) Получение из файла сведений о нем (в переменную text_info), очистка текста файла (в переменную cleaned_dd_text)\n",
    "#2) Разбивка текста на предложения (sentence_list)\n",
    "#3) Использование Mystem для получения части речи, леммы, словоформы\n",
    "#4) Кроме того, сразу же были сформированы биграммы и триграммы для записи в бд\n",
    "\n",
    "def db_create(db_conn: sqlite3.Connection):\n",
    "  dir_path = os.getcwd() + \"/texts000\"\n",
    "\n",
    "  mystem = Mystem()\n",
    "\n",
    "  for filename in glob.glob(os.path.join(dir_path, \"*.shtml\")):\n",
    "    with open(os.path.join(dir_path, filename), 'r', encoding=\"windows-1251\") as fhtml:\n",
    "      print(\"processing {filik}\".format(filik=filename))\n",
    "      db_cur = db_conn.cursor()\n",
    "\n",
    "      contents = fhtml.read()\n",
    "      soup = BeautifulSoup(contents, 'html.parser')\n",
    "\n",
    "      text_info = soup.find(\"title\").string\n",
    "    \n",
    "      db_cur.execute(\n",
    "        \"INSERT INTO text (text_info) VALUES(?) ON CONFLICT(text_info) DO NOTHING RETURNING text_id;\", (text_info, ))\n",
    "      text_id = db_cur.fetchone()\n",
    "      if text_id is None:\n",
    "        text_id = db_cur.execute(\"SELECT text_id FROM text WHERE text_info=?\", (text_info, )).fetchone()\n",
    "      text_id = text_id[0]\n",
    "\n",
    "      all_dd_text = soup.dd.text\n",
    "\n",
    "      cleaned_dd_text = all_dd_text.replace(\"\\n\", '')\n",
    "      cleaned_dd_text = cleaned_dd_text.replace(\"\\xa0\", '')\n",
    "\n",
    "      sentence_list = nltk.sent_tokenize(cleaned_dd_text)\n",
    "\n",
    "      for sentence in sentence_list:\n",
    "        sent_text = sentence\n",
    "        db_cur.execute(\"INSERT INTO sentence (text_id,sent_text) VALUES(?,?) RETURNING sent_id;\", (text_id, sent_text))\n",
    "        sent_id = db_cur.fetchone()[0]\n",
    "\n",
    "        ma_list = mystem.analyze(sentence)\n",
    "        word_index = 0\n",
    "        prev_words = [None, None]\n",
    "        for w_analyse in ma_list:\n",
    "          word_form = w_analyse.get('text', '').lower()\n",
    "          analyze_list = w_analyse.get('analysis', [])\n",
    "          if len(analyze_list) > 1:\n",
    "            pass\n",
    "\n",
    "          if len(analyze_list) > 0:\n",
    "            for analyze_dict in analyze_list:\n",
    "              lemma = analyze_dict.get('lex', 'EMPTY')\n",
    "              gr = analyze_dict.get('gr', '')\n",
    "              pos_tag = (gr.split(\"=\")[0].split(\",\")[0]) if len(gr) > 0 else ''\n",
    "            \n",
    "#Для наглядности прогресса обработки данных \n",
    "              print(text_id, sent_id, sent_text, word_form, lemma, pos_tag)\n",
    "\n",
    "              db_cur.execute(\"INSERT INTO word (lemma,pos_tag) VALUES(?,?) ON CONFLICT(lemma,pos_tag) DO NOTHING RETURNING word_id;\", (lemma, pos_tag))\n",
    "              word_id = db_cur.fetchone()\n",
    "              if word_id is None:\n",
    "                word_id = db_cur.execute(\"SELECT word_id FROM word WHERE lemma=? AND pos_tag = ?\", (lemma, pos_tag)).fetchone()\n",
    "              word_id = word_id[0]\n",
    "\n",
    "              db_cur.execute(\"INSERT OR IGNORE INTO onegramm (sent_id,word_index,word_id,word_form) VALUES(?,?,?,?);\", (sent_id, word_index, word_id, word_form))\n",
    "\n",
    "              if word_index > 0:\n",
    "                word1_id, word1_form = prev_words[1]\n",
    "                db_cur.execute(\"INSERT OR IGNORE INTO bigramm (sent_id,word_index,word1_id,word1_form,word2_id,word2_form)\"\n",
    "                               \" VALUES(?,?,?,?,?,?);\", (sent_id, word_index-1, word1_id, word1_form, word_id, word_form))\n",
    "\n",
    "              if word_index > 1:\n",
    "                word1_id, word1_form = prev_words[0]\n",
    "                word2_id, word2_form = prev_words[1]\n",
    "                db_cur.execute(\"INSERT OR IGNORE INTO trigramm (sent_id,word_index,word1_id,word1_form,word2_id,word2_form,word3_id,word3_form)\"\n",
    "                               \" VALUES(?,?,?,?,?,?,?,?);\", (sent_id, word_index-2, word1_id, word1_form, word2_id, word2_form, word_id, word_form))\n",
    "\n",
    "#Для построения биграмм и триграмм сохранялись предыдущие слова относительно анализируемого\n",
    "            word_index += 1\n",
    "            prev_words.append(tuple([word_id, word_form]))\n",
    "            prev_words.pop(0)\n",
    "\n",
    "  db_conn.commit()\n",
    "\n",
    "\n",
    "def db_main():\n",
    "  db_name = \"f_corpus.sqlite\"\n",
    "  db_conn = get_db_connect(db_name)\n",
    "  db_create(db_conn)\n",
    "\n",
    "  db_conn.close()\n",
    "\n",
    "\n",
    "db_main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3a4175c",
   "metadata": {},
   "source": [
    "### Функция поиска"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "889a6422",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pymystem3\n",
      "  Using cached pymystem3-0.2.0-py3-none-any.whl (10 kB)\n",
      "Requirement already satisfied: requests in c:\\users\\uberk\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from pymystem3) (2.27.1)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\uberk\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from requests->pymystem3) (1.26.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\uberk\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from requests->pymystem3) (2021.10.8)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\uberk\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from requests->pymystem3) (2.0.12)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\uberk\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from requests->pymystem3) (3.3)\n",
      "Installing collected packages: pymystem3\n",
      "Successfully installed pymystem3-0.2.0\n"
     ]
    }
   ],
   "source": [
    "! pip install pymystem3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9845ac35",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "from pymystem3 import Mystem\n",
    "\n",
    "\n",
    "def get_db_read_connect(db_name):\n",
    "  conn = sqlite3.connect(db_name)\n",
    "  return conn\n",
    "\n",
    "def get_word_condition(num: int, word: str):\n",
    "    \n",
    "  mystem=Mystem()\n",
    "\n",
    "#Если требовалось найти определенную словоформу\n",
    "\n",
    "  sql_where = '' \n",
    "    \n",
    "  if word.startswith('\"'):  # word form condition\n",
    "    word_form = word[1:-1]\n",
    "    word_form = word_form.lower()\n",
    "    sql_where = \"form{num}='{frm}'\".format(num=num, frm=word_form)\n",
    "    \n",
    "  else:#Если требовалось найти по лемме\n",
    "    lemma = mystem.lemmatize(word)[0]\n",
    "    \n",
    "    sql_where = \"lem{num}='{lem}'\".format(num=num, lem=lemma)\n",
    "\n",
    "  return sql_where\n",
    "\n",
    "\n",
    "def db_search_main():\n",
    "  pos_tag_set = {\"A\", \"ADV\", \"ADVPRO\", \"ANUM\", \"APRO\", \"COM\", \"CONJ\", \"INTJ\", \"NUM\", \"PART\", \"PR\", \"S\", \"SPRO\", \"V\"}\n",
    "\n",
    "  print('Для ввода словоформы напишите слово в кавычках (например, \"смешной\")')\n",
    "  print('Для ввода леммы напишите слово без кавычек (например, смешной)')\n",
    "  print('Для поиска части речи, пожалуйста, введите тэг (A, ADV, ADVPRO, ANUM, APRO, COM, CONJ, INTJ, NUM, PART, PR, S, SPRO, V) (например, V)')\n",
    "  print('Для поиска леммы или словоформы определнной части речи напишите между ними + (например, \"гуляю\"+V)')\n",
    "  print('Максимальная длина запроса 3, вводите элементы через пробел')\n",
    "\n",
    "  query = input()\n",
    "  # query = 'V \"мне\"+SPRO S'\n",
    "  # query = 'V \"мне\"'\n",
    "  # query = 'V'\n",
    "\n",
    "#Анализ введенного запроса, исходя из его длины\n",
    "  token_list = query.split(' ')\n",
    "  if len(token_list) == 1:\n",
    "    sql_select = \"SELECT t.text_id,t.text_info,s.sent_text\" \\\n",
    "                 \",g1.word_form AS form1,w1.lemma AS lem1,w1.pos_tag AS pos1\" \\\n",
    "                 \" FROM text AS t\" \\\n",
    "                 \" INNER JOIN sentence AS s on s.text_id=t.text_id\" \\\n",
    "                 \" INNER JOIN onegramm AS g1 on g1.sent_id=s.sent_id\" \\\n",
    "                 \" INNER JOIN word AS w1 on w1.word_id=g1.word_id\"\n",
    "  elif len(token_list) == 2:\n",
    "    sql_select = \"SELECT t.text_id,t.text_info,s.sent_text\" \\\n",
    "                 \",g2.word1_form AS form1,w1.lemma AS lem1,w1.pos_tag AS pos1\" \\\n",
    "                 \",g2.word2_form AS form2,w2.lemma AS lem2,w2.pos_tag AS pos2\" \\\n",
    "                 \" FROM text AS t\" \\\n",
    "                 \" INNER JOIN sentence AS s on s.text_id=t.text_id\" \\\n",
    "                 \" INNER JOIN bigramm AS g2 on g2.sent_id=s.sent_id\" \\\n",
    "                 \" INNER JOIN word AS w1 on w1.word_id=g2.word1_id\" \\\n",
    "                 \" INNER JOIN word AS w2 on w2.word_id=g2.word2_id\"\n",
    "  elif len(token_list) == 3:\n",
    "    sql_select = \"SELECT t.text_id,t.text_info,s.sent_text\" \\\n",
    "                 \",g3.word1_form AS form1,w1.lemma AS lem1,w1.pos_tag AS pos1\" \\\n",
    "                 \",g3.word2_form AS form2,w2.lemma AS lem2,w2.pos_tag AS pos2\" \\\n",
    "                 \",g3.word3_form AS form3,w3.lemma AS lem3,w3.pos_tag AS pos3\" \\\n",
    "                 \" FROM text AS t\" \\\n",
    "                 \" INNER JOIN sentence AS s on s.text_id=t.text_id\" \\\n",
    "                 \" INNER JOIN trigramm AS g3 on g3.sent_id=s.sent_id\" \\\n",
    "                 \" INNER JOIN word AS w1 on w1.word_id=g3.word1_id\" \\\n",
    "                 \" INNER JOIN word AS w2 on w2.word_id=g3.word2_id\" \\\n",
    "                 \" INNER JOIN word AS w3 on w3.word_id=g3.word3_id\"\n",
    "  else:\n",
    "    print('Некорректный запрос, в следующий раз введите запрос длиной от 1 до 3')\n",
    "    exit()\n",
    "\n",
    "  token_num = 1\n",
    "  sql_where_list = [] #Составление запроса в бд\n",
    "\n",
    "    #Анализ каждого ввденного элемента запроса (ввели лемму/словоформу/часть речи)\n",
    "  for token in token_list:\n",
    "    if token in pos_tag_set:  # POS tag\n",
    "      sql_where_list.append(\"pos{num}='{tkn}'\".format(num=token_num, tkn=token))\n",
    "    elif '+' in token:        # word+POS_tag\n",
    "      word, pos_tag = tuple(token.split('+'))\n",
    "      sql_where_list.append(get_word_condition(token_num, word))\n",
    "      sql_where_list.append(\"pos{num}='{tkn}'\".format(num=token_num, tkn=pos_tag))\n",
    "    else:                     # word form\n",
    "      sql_where_list.append(get_word_condition(token_num, token))\n",
    "\n",
    "    token_num += 1\n",
    "\n",
    "    #Отправка запроса в бд\n",
    "  db_name = \"f_corpus.sqlite\"\n",
    "  sql_query = sql_select + ' WHERE ' + \" AND \".join(sql_where_list)\n",
    "\n",
    "\n",
    "  db_conn = get_db_read_connect(db_name)\n",
    "  db_cur = db_conn.cursor()\n",
    "\n",
    "  db_cur.execute(sql_query)\n",
    "  row_list = db_cur.fetchall()\n",
    "  db_conn.close()\n",
    "\n",
    "  if len(row_list) == 0:\n",
    "    print('Увы, ничего не нашлось:(')\n",
    "\n",
    "  row_num = 1\n",
    "  for row in row_list:\n",
    "    print(row_num, ') Мета-информация: ', row[1])\n",
    "    print('Предложение: ', row[2])\n",
    "    row_num += 1\n",
    "\n",
    "\n",
    "db_search_main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90cb27f4",
   "metadata": {},
   "source": [
    "В презентации проекта более подробно будет сказано о схеме базы данных, примерах запросов, проблемах, которые возникли, предложениях по оптимзации кода."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
